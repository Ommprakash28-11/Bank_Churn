# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j7EviM2wRDOJcgoKLl0aQOrUvJjSIrfK
"""

#step 1:Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#step 2:Read Dataset
df = pd.read_csv('https://github.com/ybifoundation/Dataset/raw/main/Bank%20Churn%20Modelling.csv')

df.head()

df.info()

#missing value
df.isna().sum()

df.Geography.value_counts()

df.Gender.value_counts()

# Step 3: Define y and X
df.columns

y = df[['Churn']]
X = df[['CreditScore', 'Geography', 'Gender', 'Age',
       'Tenure', 'Balance', 'Num Of Products', 'Has Credit Card',
       'Is Active Member', 'Estimated Salary']]

# Encoding: Dummy variable
X = pd.get_dummies(X).astype('float')

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state = 2529)

# Feature scaling
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X_train= ss.fit_transform(X_train)
X_test = ss.transform(X_test)

# Model
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense

X.shape[1]

model = Sequential()
model.add(Input(shape=(X.shape[1],)))
model.add(Dense(26, activation = 'relu'))
model.add(Dense(13, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(optimizer = 'adam',loss = 'binary_crossentropy')

model.fit(X_train,y_train, epochs = 10, batch_size=32)

y_pred = np.round(model.predict(X_test))

# Evaluate
from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))